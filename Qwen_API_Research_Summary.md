# Qwenå¤§æ¨¡å‹APIå®Œæ•´è°ƒç ”æ€»ç»“

## ä¸€ã€å®˜æ–¹APIæ¥å£æ–‡æ¡£

### 1.1 åŸºç¡€APIè°ƒç”¨æ–¹æ³•

Qwen APIæ”¯æŒ**ä¸¤ç§è°ƒç”¨åè®®**ï¼š

#### **OpenAIå…¼å®¹åè®®** ï¼ˆæ¨èï¼‰
- ä¸OpenAI APIæ ¼å¼å®Œå…¨å…¼å®¹
- æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€çš„OpenAI SDK
- è¯·æ±‚åœ°å€ï¼š`POST /chat/completions`
- ä¼˜ç‚¹ï¼šæ— ç¼è¿ç§»ã€ç”Ÿæ€æˆç†Ÿ

#### **DashScopeåè®®** ï¼ˆé˜¿é‡Œäº‘åŸç”Ÿï¼‰
- é˜¿é‡Œäº‘ä¸“é—¨çš„åè®®
- æ”¯æŒä¸“é—¨çš„DashScope SDK
- è¯·æ±‚åœ°å€ï¼š`POST /services/aigc/text-generation/generation`

#### **åœ°åŸŸç«¯ç‚¹**
```
ååŒ—2ï¼ˆåŒ—äº¬ï¼‰:
  OpenAIå…¼å®¹: https://dashscope.aliyuncs.com/compatible-mode/v1
  DashScope: https://dashscope.aliyuncs.com/api/v1

æ–°åŠ å¡:
  OpenAIå…¼å®¹: https://dashscope-intl.aliyuncs.com/compatible-mode/v1
  DashScope: https://dashscope-intl.aliyuncs.com/api/v1

ç¾å›½ï¼ˆå¼—å‰å°¼äºšï¼‰:
  OpenAIå…¼å®¹: https://dashscope-us.aliyuncs.com/compatible-mode/v1
  DashScope: https://dashscope-us.aliyuncs.com/api/v1

é‡‘èäº‘:
  OpenAIå…¼å®¹: https://dashscope-finance.aliyuncs.com/compatible-mode/v1
  DashScope: https://dashscope-finance.aliyuncs.com/api/v1
```

### 1.2 é‰´æƒæ–¹å¼

æ‰€æœ‰APIè¯·æ±‚éƒ½éœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«API Keyï¼š

```
Authorization: Bearer {API_KEY}
```

**è·å–æ–¹å¼ï¼š**
- è®¿é—®é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°ï¼šhttps://bailian.console.aliyun.com
- åˆ›å»ºAPI Key
- å»ºè®®é…ç½®ç¯å¢ƒå˜é‡ï¼š`export DASHSCOPE_API_KEY="sk-xxx"`

### 1.3 æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹ç³»åˆ— | å…·ä½“æ¨¡å‹ | ç”¨é€”è¯´æ˜ | ç‰¹ç‚¹ |
|---------|--------|--------|------|
| **é€šç”¨æ¨¡å‹** | qwen-max, qwen-max-latest | é«˜æ€§èƒ½é€šç”¨ | å»¶æ—¶çº¦500msï¼Œæ€§èƒ½æœ€å¼º |
| | qwen-plus, qwen-plus-latest | é€šç”¨æ¨¡å‹ | æ€§ä»·æ¯”æœ€é«˜ï¼Œåº”ç”¨æœ€å¹¿ |
| | qwen-flash, qwen-flash-latest | è½»é‡çº§ | å“åº”æœ€å¿«ï¼Œæ¶ˆè€—æœ€å°‘ |
| | qwen-turbo, qwen-turbo-latest | å¿«é€Ÿå“åº” | æŠ˜ä¸­æ–¹æ¡ˆ |
| **ç¼–ç¨‹æ¨¡å‹** | qwen-coder-plus, qwen-coder-turbo | ä»£ç ç”Ÿæˆ/ç†è§£ | ç¼–ç¨‹èƒ½åŠ›ä¸“å¼º |
| | qwen-1.8b-chat | æè½»é‡ | ç§»åŠ¨ç«¯/è¾¹ç¼˜éƒ¨ç½² |
| **ä¸“ä¸šæ¨¡å‹** | qwen-math-plus, qwen-math-turbo | æ•°å­¦æ±‚è§£ | æ•°å­¦æ¨ç†ä¸“é•¿ |
| | qwen-medicine-32b/7b/3b | åŒ»å­¦é—®é¢˜ | åŒ»å­¦é¢†åŸŸ |
| | qwen-writing-32b/7b/3b | å†™ä½œåˆ›æ„ | æ–‡æ¡ˆç”Ÿæˆ |
| **è§†è§‰æ¨¡å‹** | qwen-vl-max, qwen-vl-plus | å›¾åƒ/è§†é¢‘ç†è§£ | å¤šæ¨¡æ€è¾“å…¥ |
| | qvq-72b-preview | è§†è§‰æ¨ç† | è§†è§‰æ¨ç†ä¸“å¼º |
| **é•¿æ–‡æœ¬æ¨¡å‹** | qwen-long | é•¿æ–‡æœ¬ç†è§£ | å¤„ç†è¶…é•¿æ–‡æ¡£ |
| **æ¨ç†æ¨¡å‹** | qwq-32b-preview | æ·±åº¦æ¨ç† | æ€ç»´é“¾æ¨ç† |
| **å…¨æ¨¡æ€æ¨¡å‹** | qwen-omni-turbo | æ–‡æœ¬+éŸ³é¢‘+è§†é¢‘ | ç«¯åˆ°ç«¯å…¨æ¨¡æ€å¤„ç† |
| | qwen2-audio-instruct | éŸ³é¢‘ç†è§£ | è¯­éŸ³è¯†åˆ«å’Œç†è§£ |

### 1.4 è¯·æ±‚/å“åº”æ ¼å¼

#### **OpenAIå…¼å®¹åè®® - è¯·æ±‚æ ¼å¼**

```json
{
  "model": "qwen-plus",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "ä½ æ˜¯è°ï¼Ÿ"
    }
  ],
  "temperature": 0.7,
  "top_p": 0.8,
  "max_tokens": 2000,
  "stream": false
}
```

#### **è¯·æ±‚å‚æ•°è¯¦è§£**

| å‚æ•° | ç±»å‹ | å¿…é€‰ | è¯´æ˜ | å–å€¼èŒƒå›´ |
|------|------|------|------|---------|
| model | string | âœ“ | æ¨¡å‹åç§° | qwen-plus/maxç­‰ |
| messages | array | âœ“ | å¯¹è¯æ¶ˆæ¯æ•°ç»„ | æ¯æ¡åŒ…æ‹¬roleå’Œcontent |
| temperature | float | âœ— | é‡‡æ ·æ¸©åº¦ | [0, 2) é»˜è®¤0.7 |
| top_p | float | âœ— | æ ¸é‡‡æ ·æ¦‚ç‡ | (0, 1.0] é»˜è®¤0.8 |
| max_tokens | integer | âœ— | æœ€å¤§è¾“å‡ºTokenæ•° | æ ¹æ®æ¨¡å‹é™åˆ¶ |
| stream | boolean | âœ— | æ˜¯å¦æµå¼è¾“å‡º | é»˜è®¤false |
| enable_search | boolean | âœ— | å¯ç”¨è”ç½‘æœç´¢ | é»˜è®¤false |
| tools | array | âœ— | Function Callingå·¥å…·åˆ—è¡¨ | - |
| top_k | integer | âœ— | Top-Ké‡‡æ · | é»˜è®¤æ— é™åˆ¶ |
| presence_penalty | float | âœ— | å­˜åœ¨æƒ©ç½š | [-2, 2] |
| frequency_penalty | float | âœ— | é¢‘ç‡æƒ©ç½š | [-2, 2] |

#### **éæµå¼å“åº”æ ¼å¼**

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1735120033,
  "model": "qwen-plus",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "æˆ‘æ˜¯é˜¿é‡Œäº‘å¼€å‘çš„é€šä¹‰åƒé—®ã€‚"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 3019,
    "completion_tokens": 104,
    "total_tokens": 3123
  }
}
```

#### **æµå¼å“åº”æ ¼å¼**

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion.chunk",
  "created": 1735113344,
  "model": "qwen-plus",
  "choices": [
    {
      "index": 0,
      "delta": {
        "role": "assistant",
        "content": "æˆ‘æ˜¯"
      },
      "finish_reason": null
    }
  ]
}
```

#### **å“åº”å­—æ®µè¯´æ˜**

| å­—æ®µ | è¯´æ˜ |
|------|------|
| id | æœ¬æ¬¡è°ƒç”¨çš„å”¯ä¸€æ ‡è¯†ç¬¦ |
| choices | æ¨¡å‹ç”Ÿæˆå†…å®¹æ•°ç»„ |
| choices[].message.content | æ¨¡å‹çš„å›å¤å†…å®¹ |
| choices[].finish_reason | åœæ­¢åŸå› ï¼š`stop`ï¼ˆæ­£å¸¸ï¼‰ã€`length`ï¼ˆè¶…é•¿ï¼‰ã€`tool_calls`ï¼ˆå·¥å…·è°ƒç”¨ï¼‰ |
| usage.prompt_tokens | è¾“å…¥Tokenæ•° |
| usage.completion_tokens | è¾“å‡ºTokenæ•° |
| usage.total_tokens | æ€»Tokenæ•° |

---

## äºŒã€ä¸»è¦æ¥å£ç±»å‹

### 2.1 æ–‡æœ¬ç”Ÿæˆ/å¯¹è¯æ¥å£

**åŸºæœ¬ç‰¹ç‚¹ï¼š**
- æ”¯æŒå¤šè½®å¯¹è¯
- å®Œæ•´çš„ä¸Šä¸‹æ–‡ç†è§£
- æ”¯æŒè§’è‰²è®¾å®š

**é€‚ç”¨åœºæ™¯ï¼š**
- èŠå¤©æœºå™¨äºº
- é—®ç­”ç³»ç»Ÿ
- å†…å®¹ç”Ÿæˆ

### 2.2 æµå¼å“åº”æ¥å£

**ç‰¹ç‚¹ï¼š**
- å®æ—¶è¿”å›æ•°æ®
- ç”¨æˆ·ä½“éªŒå¥½
- é€‚åˆUIå±•ç¤º

**å…³é”®å‚æ•°ï¼š**
```python
stream=True  # å¯ç”¨æµå¼
stream_options={"include_usage": True}  # è·å–Tokenç»Ÿè®¡
```

### 2.3 Function Callingï¼ˆå‡½æ•°è°ƒç”¨ï¼‰æ¥å£

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- è®©æ¨¡å‹åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å¤–éƒ¨å·¥å…·
- æ¨¡å‹è¿”å›å·¥å…·åå’Œå‚æ•°
- æ”¯æŒå¹¶è¡Œå·¥å…·è°ƒç”¨

**å·¥ä½œæµç¨‹ï¼š**
1. ç¬¬ä¸€æ­¥ï¼šå‘é€ç”¨æˆ·é—®é¢˜+å·¥å…·æ¸…å•ç»™æ¨¡å‹
2. ç¬¬äºŒæ­¥ï¼šæ¨¡å‹è¿”å›éœ€è¦è°ƒç”¨çš„å·¥å…·å’Œå‚æ•°
3. ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨ç«¯æ‰§è¡Œå·¥å…·ï¼Œè·å¾—ç»“æœ
4. ç¬¬å››æ­¥ï¼šå°†å·¥å…·ç»“æœå›ä¼ ç»™æ¨¡å‹
5. ç¬¬äº”æ­¥ï¼šæ¨¡å‹æ•´åˆä¿¡æ¯è¿”å›æœ€ç»ˆç­”æ¡ˆ

**æ”¯æŒçš„æ¨¡å‹ï¼š**
- qwen-maxã€qwen-plusã€qwen-flashç­‰å…¨ç³»
- å…¶ä»–å‚å•†ï¼šdeepseek-v3.2ã€glm-4.7ã€kimi-k2ç­‰

### 2.4 é«˜çº§åŠŸèƒ½

| åŠŸèƒ½ | è¯´æ˜ | åº”ç”¨åœºæ™¯ |
|------|------|---------|
| è”ç½‘æœç´¢ | `enable_search=true` | å®æ—¶ä¿¡æ¯æŸ¥è¯¢ |
| å¤šæ¨¡æ€è¾“å…¥ | å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ | å†…å®¹åˆ†æ |
| é•¿æ–‡æœ¬å¤„ç† | qwen-longæ¨¡å‹ | æ–‡æ¡£ç†è§£ã€æ€»ç»“ |
| è§†è§‰æ¨ç† | qvqæ¨¡å‹ | å›¾è¡¨åˆ†æã€OCR |
| éŸ³é¢‘å¤„ç† | qwen-omniç³»åˆ— | è¯­éŸ³è¯†åˆ«ã€è½¬å½• |

---

## ä¸‰ã€Pythonè°ƒç”¨ç¤ºä¾‹

### 3.1 SDKå®‰è£…

```bash
# æ–¹å¼ä¸€ï¼šOpenAI SDKï¼ˆæ¨èï¼‰
pip install -U openai

# æ–¹å¼äºŒï¼šé˜¿é‡Œäº‘DashScope SDK
pip install dashscope

# æ–¹å¼ä¸‰ï¼šä½¿ç”¨LangChain
pip install langchain-community
```

### 3.2 åŸºæœ¬è°ƒç”¨ç¤ºä¾‹ï¼ˆOpenAIå…¼å®¹ï¼‰

```python
import os
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),  # ä»ç¯å¢ƒå˜é‡è¯»å–
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# å‘é€è¯·æ±‚
response = client.chat.completions.create(
    model="qwen-plus",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—"}
    ],
    temperature=0.7,
    max_tokens=2000
)

# è·å–å›å¤
print(response.choices[0].message.content)

# è·å–Tokenç»Ÿè®¡
print(f"è¾“å…¥Token: {response.usage.prompt_tokens}")
print(f"è¾“å‡ºToken: {response.usage.completion_tokens}")
print(f"æ€»Token: {response.usage.total_tokens}")
```

### 3.3 æµå¼è°ƒç”¨ç¤ºä¾‹

```python
import os
import json
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# æµå¼è°ƒç”¨
stream = client.chat.completions.create(
    model="qwen-plus",
    messages=[
        {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
    ],
    stream=True,
    stream_options={"include_usage": True}  # è·å–æœ€ç»ˆTokenç»Ÿè®¡
)

# å¤„ç†æµå¼å“åº”
print("å¼€å§‹æ¥æ”¶æµå¼æ•°æ®ï¼š\n")
total_tokens = 0

for chunk in stream:
    # æ£€æŸ¥æ˜¯å¦æœ‰deltaå†…å®¹
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
    
    # è·å–æœ€åçš„Tokenç»Ÿè®¡
    if chunk.usage:
        print(f"\n\n=== è°ƒç”¨ç»Ÿè®¡ ===")
        print(f"è¾“å…¥Token: {chunk.usage.prompt_tokens}")
        print(f"è¾“å‡ºToken: {chunk.usage.completion_tokens}")
        print(f"æ€»Token: {chunk.usage.total_tokens}")
```

### 3.4 Function Callingç¤ºä¾‹

```python
from openai import OpenAI
import json
import os

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# å®šä¹‰å·¥å…·åˆ—è¡¨
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œå¦‚åŒ—äº¬ã€ä¸Šæµ·ç­‰"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½"
                    }
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "æ‰§è¡Œæ•°å­¦è®¡ç®—",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "æ•°å­¦è¡¨è¾¾å¼"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

# æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
def get_current_weather(location, unit="celsius"):
    """æ¨¡æ‹Ÿå¤©æ°”æŸ¥è¯¢"""
    weather_data = {
        "åŒ—äº¬": {"temp": 5, "description": "æ™´æœ—"},
        "ä¸Šæµ·": {"temp": 12, "description": "å¤šäº‘"}
    }
    data = weather_data.get(location, {"temp": 20, "description": "æœªçŸ¥"})
    return f"{location}å¤©æ°”ï¼š{data['description']}ï¼Œæ¸©åº¦{data['temp']}Â°{unit[0].upper()}"

def calculate(expression):
    """æ‰§è¡Œè®¡ç®—"""
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœï¼š{result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯ï¼š{str(e)}"

# ç¬¬ä¸€æ­¥ï¼šå‘é€ç”¨æˆ·é—®é¢˜å’Œå·¥å…·åˆ—è¡¨
messages = [{"role": "user", "content": "åŒ—äº¬ç°åœ¨å¤šå°‘åº¦ï¼Ÿè®¡ç®—ä¸€ä¸‹2+2ç­‰äºå¤šå°‘"}]

response = client.chat.completions.create(
    model="qwen-plus",
    messages=messages,
    tools=tools,
)

assistant_message = response.choices[0].message
messages.append(assistant_message)

# ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
if assistant_message.tool_calls:
    print(f"æ¨¡å‹åˆ¤æ–­éœ€è¦è°ƒç”¨ä»¥ä¸‹å·¥å…·ï¼š")
    
    # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
    tool_results = []
    for tool_call in assistant_message.tool_calls:
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments)
        
        print(f"\n  - å·¥å…·ï¼š{tool_name}")
        print(f"    å‚æ•°ï¼š{tool_args}")
        
        # æ ¹æ®å·¥å…·åæ‰§è¡Œç›¸åº”å‡½æ•°
        if tool_name == "get_current_weather":
            result = get_current_weather(**tool_args)
        elif tool_name == "calculate":
            result = calculate(**tool_args)
        else:
            result = "å·¥å…·ä¸å­˜åœ¨"
        
        print(f"    ç»“æœï¼š{result}")
        
        # ä¿å­˜å·¥å…·ç»“æœ
        tool_results.append({
            "role": "tool",
            "tool_call_id": tool_call.id,
            "content": result
        })
    
    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
    messages.extend(tool_results)
    
    # ç¬¬ä¸‰æ­¥ï¼šå†æ¬¡è°ƒç”¨æ¨¡å‹è·å–æœ€ç»ˆç­”æ¡ˆ
    print("\næ­£åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
    final_response = client.chat.completions.create(
        model="qwen-plus",
        messages=messages,
        tools=tools,
    )
    
    print(f"\næœ€ç»ˆç­”æ¡ˆï¼š{final_response.choices[0].message.content}")
else:
    print(f"æ¨¡å‹æ— éœ€è°ƒç”¨å·¥å…·ï¼Œç›´æ¥å›å¤ï¼š{assistant_message.content}")
```

### 3.5 é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
from openai import OpenAI, APIError, RateLimitError, APIConnectionError
import os
import time

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

def call_qwen_with_retry(messages, max_retries=3, retry_delay=2):
    """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="qwen-plus",
                messages=messages,
                temperature=0.7,
                max_tokens=2000,
                timeout=30  # 30ç§’è¶…æ—¶
            )
            return response
        
        except RateLimitError as e:
            # è§¦å‘é™æµ
            if attempt < max_retries - 1:
                wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                print(f"è§¦å‘é™æµï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                print(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè§¦å‘é™æµï¼š{str(e)}")
                raise
        
        except APIConnectionError as e:
            # ç½‘ç»œè¿æ¥é”™è¯¯
            if attempt < max_retries - 1:
                print(f"ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼š{str(e)}")
                raise
        
        except APIError as e:
            # å…¶ä»–APIé”™è¯¯
            if "401" in str(e):
                print("é”™è¯¯ï¼šAPI Keyæ— æ•ˆæˆ–å·²è¿‡æœŸ")
                raise
            elif "400" in str(e):
                print("é”™è¯¯ï¼šè¯·æ±‚å‚æ•°ä¸åˆæ³•")
                raise
            elif "503" in str(e):
                # æœåŠ¡å™¨ç¹å¿™
                if attempt < max_retries - 1:
                    print(f"æœåŠ¡å™¨ç¹å¿™ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    print("æœåŠ¡å™¨ç¹å¿™ï¼Œæ— æ³•å®Œæˆè¯·æ±‚")
                    raise
            else:
                print(f"APIé”™è¯¯ï¼š{str(e)}")
                raise
        
        except Exception as e:
            # æ•è·æ‰€æœ‰å…¶ä»–å¼‚å¸¸
            print(f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}")
            raise

# ä½¿ç”¨ç¤ºä¾‹
try:
    messages = [
        {"role": "user", "content": "ä½ å¥½"}
    ]
    
    response = call_qwen_with_retry(messages)
    print(f"å›å¤ï¼š{response.choices[0].message.content}")
    
except Exception as e:
    print(f"æœ€ç»ˆå¤±è´¥ï¼š{str(e)}")
```

### 3.6 å¤šè½®å¯¹è¯ç¤ºä¾‹

```python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

def multi_turn_conversation():
    """å¤šè½®å¯¹è¯ç¤ºä¾‹"""
    
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·è§£ç­”ç¼–ç¨‹é—®é¢˜ã€‚"
        }
    ]
    
    print("å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥'exit'é€€å‡ºï¼‰ï¼š\n")
    
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("ç”¨æˆ·ï¼š").strip()
        
        if user_input.lower() == "exit":
            print("å¯¹è¯ç»“æŸ")
            break
        
        if not user_input:
            continue
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_input})
        
        # è°ƒç”¨API
        response = client.chat.completions.create(
            model="qwen-plus",
            messages=messages,
            temperature=0.7
        )
        
        # è·å–åŠ©æ‰‹å›å¤
        assistant_reply = response.choices[0].message.content
        messages.append({"role": "assistant", "content": assistant_reply})
        
        # æ˜¾ç¤ºå›å¤
        print(f"åŠ©æ‰‹ï¼š{assistant_reply}\n")
        
        # æ˜¾ç¤ºTokenæ¶ˆè€—
        print(f"[Tokenæ¶ˆè€—] è¾“å…¥:{response.usage.prompt_tokens} è¾“å‡º:{response.usage.completion_tokens}")
        print("-" * 60 + "\n")

if __name__ == "__main__":
    multi_turn_conversation()
```

---

## å››ã€å¸¸è§ç”¨ä¾‹å’Œæœ€ä½³å®è·µ

### 4.1 æç¤ºè¯ä¼˜åŒ–

#### **åŸåˆ™1ï¼šæ¸…æ™°çš„è§’è‰²å®šä¹‰**

```python
# âŒ ä¸å¥½çš„ä¾‹å­
messages=[
    {"role": "user", "content": "ä½ èƒ½å¸®æˆ‘å—ï¼Ÿ"}
]

# âœ… å¥½çš„ä¾‹å­
messages=[
    {
        "role": "system", 
        "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ•°æ®åˆ†æå¸ˆï¼Œæ‹¥æœ‰10å¹´çš„è¡Œä¸šç»éªŒã€‚ä½ çš„å›ç­”éœ€è¦ä¸“ä¸šã€å‡†ç¡®ã€æ˜“æ‡‚ã€‚"
    },
    {"role": "user", "content": "å¦‚ä½•åˆ†æç”¨æˆ·æµå¤±ç‡ï¼Ÿ"}
]
```

#### **åŸåˆ™2ï¼šå…·ä½“åŒ–éœ€æ±‚**

```python
# âŒ ä¸å¥½çš„ä¾‹å­
{"role": "user", "content": "å†™ä¸€ä¸ªå‡½æ•°"}

# âœ… å¥½çš„ä¾‹å­
{
    "role": "user",
    "content": """
    å†™ä¸€ä¸ªPythonå‡½æ•°ï¼Œå®ç°å¿«é€Ÿæ’åºç®—æ³•ï¼Œè¦æ±‚ï¼š
    1. è¾“å…¥å‚æ•°ä¸ºä¸€ä¸ªåˆ—è¡¨
    2. è¿”å›æ’åºåçš„åˆ—è¡¨
    3. æ·»åŠ è¯¦ç»†çš„æ³¨é‡Š
    4. åŒ…å«æµ‹è¯•ç”¨ä¾‹
    """
}
```

#### **åŸåˆ™3ï¼šæä¾›ä¸Šä¸‹æ–‡**

```python
# âŒ ä¸å¥½çš„ä¾‹å­
{"role": "user", "content": "è¿™æ®µä»£ç æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ"}

# âœ… å¥½çš„ä¾‹å­
{
    "role": "user",
    "content": """
    èƒŒæ™¯ï¼šæˆ‘ä»¬åœ¨å¤„ç†ç”µå•†è®¢å•æ•°æ®
    é—®é¢˜ä»£ç ï¼š
    ```python
    orders = [100, 200, 150]
    total = sum(orders) / len(orders)
    ```
    è¿™æ®µä»£ç çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ
    """
}
```

#### **åŸåˆ™4ï¼šå°‘é‡ç¤ºä¾‹ï¼ˆFew-Shotï¼‰**

```python
# ä½¿ç”¨å°‘é‡ç¤ºä¾‹å¼•å¯¼æ¨¡å‹è¾“å‡ºæ ¼å¼
messages = [
    {
        "role": "system",
        "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®æ ‡æ³¨åŠ©æ‰‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥ç”ŸæˆJSONæ ¼å¼çš„æ ‡æ³¨ã€‚"
    },
    {
        "role": "user",
        "content": "ä»è¿™å¥è¯ä¸­æå–äººç‰©å’Œåœ°ç‚¹ï¼šå¼ ä¸‰åœ¨åŒ—äº¬ä¹°äº†ä¸€å¥—æˆ¿å­ã€‚"
    },
    {
        "role": "assistant",
        "content": '{"person": "å¼ ä¸‰", "location": "åŒ—äº¬", "action": "ä¹°æˆ¿"}'
    },
    {
        "role": "user",
        "content": "ä»è¿™å¥è¯ä¸­æå–äººç‰©å’Œåœ°ç‚¹ï¼šæå››åœ¨ä¸Šæµ·æ‰¾åˆ°äº†ä¸€ä»½å·¥ä½œã€‚"
    }
]
```

### 4.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### **1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹**

| åœºæ™¯ | æ¨èæ¨¡å‹ | ç†ç”± |
|------|--------|------|
| å®æ—¶å¯¹è¯ | qwen-flash | å»¶æ—¶ä½ï¼Œæˆæœ¬ä½ |
| å¤æ‚ä»»åŠ¡ | qwen-plus | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ |
| é«˜ç²¾åº¦éœ€æ±‚ | qwen-max | æ€§èƒ½æœ€å¼º |
| ä»£ç ä»»åŠ¡ | qwen-coder-plus | ç¼–ç¨‹èƒ½åŠ›å¼º |
| ç§»åŠ¨åº”ç”¨ | qwen-1.8b-chat | è¶…è½»é‡ |

#### **2. ä½¿ç”¨æµå¼è¾“å‡º**

```python
# ä¼˜ç‚¹ï¼š
# 1. ç”¨æˆ·æ„Ÿå—åˆ°ç«‹å³åé¦ˆ
# 2. å¯ä»¥æå‰è·å–éƒ¨åˆ†ç»“æœ
# 3. æ”¹è¿›ç”¨æˆ·ä½“éªŒ

stream = client.chat.completions.create(
    model="qwen-plus",
    messages=messages,
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

#### **3. æ§åˆ¶æ–‡æœ¬é•¿åº¦**

```python
# ä½¿ç”¨max_tokensé™åˆ¶è¾“å‡ºé•¿åº¦
response = client.chat.completions.create(
    model="qwen-plus",
    messages=messages,
    max_tokens=500  # é™åˆ¶è¾“å‡ºä¸º500 tokens
)
```

#### **4. å¹¶å‘è¯·æ±‚ç®¡ç†**

```python
import asyncio
from openai import AsyncOpenAI

async_client = AsyncOpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

async def make_request(prompt, task_id):
    """å¼‚æ­¥å‘é€å•ä¸ªè¯·æ±‚"""
    try:
        response = await async_client.chat.completions.create(
            model="qwen-plus",
            messages=[{"role": "user", "content": prompt}],
            timeout=30
        )
        return task_id, response.choices[0].message.content
    except Exception as e:
        return task_id, f"é”™è¯¯: {str(e)}"

async def batch_requests(prompts):
    """å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚"""
    tasks = [
        make_request(prompt, i)
        for i, prompt in enumerate(prompts)
    ]
    results = await asyncio.gather(*tasks)
    return results

# ä½¿ç”¨ç¤ºä¾‹
prompts = [
    "ç®€è¿°Pythonçš„ç‰¹ç‚¹",
    "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
    "è§£é‡Šä»€ä¹ˆæ˜¯REST API"
]

results = asyncio.run(batch_requests(prompts))
for task_id, result in results:
    print(f"ä»»åŠ¡{task_id}: {result}\n")
```

### 4.3 æˆæœ¬æ§åˆ¶å»ºè®®

#### **1. Tokenæ¶ˆè€—ç›‘æ§**

```python
def estimate_tokens(text):
    """ç²—ç•¥ä¼°è®¡Tokenæ•°ï¼ˆ1ä¸ªä¸­æ–‡çº¦1.5 tokensï¼Œ1ä¸ªè‹±æ–‡å•è¯çº¦1.3 tokensï¼‰"""
    chinese_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    english_words = len([w for w in text.split() if w.isalpha()])
    
    tokens = chinese_count * 1.5 + english_words * 1.3
    return int(tokens)

# ä½¿ç”¨ç¤ºä¾‹
text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­ã€‚This is a test."
print(f"é¢„ä¼°Tokenæ•°ï¼š{estimate_tokens(text)}")
```

#### **2. æˆæœ¬ä¼˜åŒ–ç­–ç•¥**

```python
def optimize_cost():
    """æˆæœ¬ä¼˜åŒ–çš„æœ€ä½³å®è·µ"""
    
    # ç­–ç•¥1ï¼šé€‰æ‹©ä»·æ ¼ä½çš„æ¨¡å‹
    # qwen-flash < qwen-plus < qwen-max
    
    # ç­–ç•¥2ï¼šå‡å°‘ä¸å¿…è¦çš„ä¸Šä¸‹æ–‡
    # åªä¿ç•™æœ€è¿‘çš„Nè½®å¯¹è¯ï¼ˆä¾‹å¦‚æœ€è¿‘5è½®ï¼‰
    def trim_messages(messages, max_rounds=5):
        # ä¿ç•™systemæ¶ˆæ¯å’Œæœ€è¿‘max_roundsè½®å¯¹è¯
        if len(messages) > max_rounds * 2 + 1:
            messages = [messages[0]] + messages[-(max_rounds*2):]
        return messages
    
    # ç­–ç•¥3ï¼šä½¿ç”¨ç¼“å­˜
    messages_cache = {}
    
    # ç­–ç•¥4ï¼šæ‰¹é‡å¤„ç†
    # åˆå¹¶å¤šä¸ªå°è¯·æ±‚ä¸ºä¸€ä¸ªå¤§è¯·æ±‚
    
    # ç­–ç•¥5ï¼šç›‘æ§Tokenä½¿ç”¨
    def track_cost(response, model="qwen-plus"):
        # qwen-plus: è¾“å…¥0.5å…ƒ/ç™¾ä¸‡tokens, è¾“å‡º1.5å…ƒ/ç™¾ä¸‡tokens
        input_cost = response.usage.prompt_tokens * 0.5 / 1000000
        output_cost = response.usage.completion_tokens * 1.5 / 1000000
        total_cost = input_cost + output_cost
        return total_cost
```

#### **3. å®šä»·å‚è€ƒï¼ˆ2025å¹´ï¼‰**

```
é€šä¹‰åƒé—® API å®šä»·å‚è€ƒï¼š
â”œâ”€ qwen-max (æœ€å¼º)
â”‚  â”œâ”€ è¾“å…¥ï¼šÂ¥0.002/1K tokens
â”‚  â””â”€ è¾“å‡ºï¼šÂ¥0.006/1K tokens
â”œâ”€ qwen-plus (æ¨è)
â”‚  â”œâ”€ è¾“å…¥ï¼šÂ¥0.0005/1K tokens
â”‚  â””â”€ è¾“å‡ºï¼šÂ¥0.0015/1K tokens
â”œâ”€ qwen-flash (è½»é‡)
â”‚  â”œâ”€ è¾“å…¥ï¼šÂ¥0.00008/1K tokens
â”‚  â””â”€ è¾“å‡ºï¼šÂ¥0.0002/1K tokens
â”œâ”€ qwen-turbo
â”‚  â”œâ”€ è¾“å…¥ï¼šÂ¥0.0002/1K tokens
â”‚  â””â”€ è¾“å‡ºï¼šÂ¥0.0006/1K tokens
â””â”€ qwen-coder-plus (ç¼–ç¨‹)
   â”œâ”€ è¾“å…¥ï¼šÂ¥0.001/1K tokens
   â””â”€ è¾“å‡ºï¼šÂ¥0.003/1K tokens

ç‰¹æ®Šæ¨¡å‹ï¼š
â”œâ”€ qwen-vl-plus (è§†è§‰): Â¥0.02-0.1/å¼ 
â”œâ”€ qwen-math (æ•°å­¦): Â¥0.001/1K tokens
â””â”€ qwq (æ¨ç†): Â¥0.002/1K tokens

æ³¨ï¼šå…·ä½“ä»·æ ¼ä»¥å®˜æ–¹ä¸ºå‡†
```

### 4.4 æœ€ä½³å®è·µæ€»ç»“

#### **å®‰å…¨æ€§**

```python
# 1. ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç API Key
# âŒ api_key = "sk-xxxxxx"

# âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡
import os
api_key = os.getenv("DASHSCOPE_API_KEY")

# 2. éªŒè¯ç”¨æˆ·è¾“å…¥
def validate_input(user_input, max_length=10000):
    """éªŒè¯ç”¨æˆ·è¾“å…¥"""
    if not user_input or len(user_input) > max_length:
        raise ValueError("è¾“å…¥è¿‡é•¿æˆ–ä¸ºç©º")
    return user_input.strip()

# 3. ä¸è¦ä¼ é€’æ•æ„Ÿä¿¡æ¯
# âŒ åŒ…å«ä¸ªäººéšç§çš„æ•°æ®
# âœ… è„±æ•æˆ–åŒ¿ååŒ–å¤„ç†
```

#### **å¯é æ€§**

```python
# 1. æ·»åŠ æ—¥å¿—è®°å½•
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 2. å®ç°é‡è¯•æœºåˆ¶
import time
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_api(messages):
    return client.chat.completions.create(
        model="qwen-plus",
        messages=messages
    )

# 3. è¶…æ—¶æ§åˆ¶
response = client.chat.completions.create(
    model="qwen-plus",
    messages=messages,
    timeout=60  # 60ç§’è¶…æ—¶
)
```

#### **ç”¨æˆ·ä½“éªŒ**

```python
# 1. æä¾›å®æ—¶åé¦ˆ
print("æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...", end="", flush=True)

# 2. ä¼˜é›…çš„é”™è¯¯æç¤º
try:
    response = client.chat.completions.create(...)
except Exception as e:
    print(f"è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚é”™è¯¯è¯¦æƒ…ï¼š{str(e)}")

# 3. æ˜¾ç¤ºå¤„ç†è¿›åº¦
for i, chunk in enumerate(stream):
    print(chunk.choices[0].delta.content or "", end="", flush=True)
    if i % 10 == 0:
        logger.info(f"å·²å¤„ç† {i} ä¸ªchunks")
```

---

## äº”ã€å¸¸è§é—®é¢˜è§£ç­”

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Ÿ

**A:** æ ¹æ®ä»¥ä¸‹ç»´åº¦é€‰æ‹©ï¼š
- **æ€§èƒ½éœ€æ±‚**ï¼šç®€å•é—®ç­”ç”¨flashï¼Œå¤æ‚ä»»åŠ¡ç”¨plus/max
- **æˆæœ¬é™åˆ¶**ï¼šé¢„ç®—æœ‰é™ç”¨flashï¼Œè¿½æ±‚è´¨é‡ç”¨plus/max
- **å»¶è¿Ÿè¦æ±‚**ï¼šéœ€è¦å®æ—¶ç”¨flashï¼Œå¯æ¥å—å»¶è¿Ÿç”¨max
- **ç‰¹æ®Šéœ€æ±‚**ï¼šä»£ç ç”¨coderï¼Œæ•°å­¦ç”¨mathï¼Œè§†è§‰ç”¨vl

### Q2: ä¸ºä»€ä¹ˆAPIè°ƒç”¨å¤±è´¥ï¼Ÿ

**A:** å¸¸è§åŸå› ï¼š
1. **401é”™è¯¯**ï¼šAPI Keyæ— æ•ˆæˆ–è¿‡æœŸ
2. **429é”™è¯¯**ï¼šè§¦å‘é™æµï¼Œå»ºè®®å®æ–½é‡è¯•æœºåˆ¶
3. **500é”™è¯¯**ï¼šæœåŠ¡å™¨é”™è¯¯ï¼Œç¨åé‡è¯•
4. **è¶…æ—¶**ï¼šç½‘ç»œé—®é¢˜æˆ–è¯·æ±‚è¿‡å¤§ï¼Œå‡å°‘max_tokens

### Q3: å¦‚ä½•é™ä½æˆæœ¬ï¼Ÿ

**A:** ä¸»è¦æ–¹æ¡ˆï¼š
1. ä½¿ç”¨qwen-flashæ›¿ä»£qwen-plus
2. å‡å°‘ä¸å¿…è¦çš„å†å²æ¶ˆæ¯
3. ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è¯·æ±‚
4. ä¼˜åŒ–æç¤ºè¯é•¿åº¦
5. ç›‘æ§Tokenæ¶ˆè€—

### Q4: æµå¼è¾“å‡ºå’Œéæµå¼çš„åŒºåˆ«ï¼Ÿ

**A:**
- **æµå¼**ï¼šå®æ—¶è¿”å›ï¼Œç”¨æˆ·ä½“éªŒå¥½ï¼Œé€‚åˆUIå±•ç¤º
- **éæµå¼**ï¼šä¸€æ¬¡è¿”å›å®Œæ•´ç»“æœï¼Œä¾¿äºå¤„ç†ç»Ÿè®¡æ•°æ®

### Q5: Function Callingä¼šé¢å¤–æ”¶è´¹å—ï¼Ÿ

**A:** ä¸ä¼šå•ç‹¬æ”¶è´¹ï¼Œä½†å·¥å…·æè¿°ä¼šè®¡å…¥Tokenæˆæœ¬ï¼Œå»ºè®®ç²¾ç®€æè¿°ã€‚

---

## å…­ã€å¿«é€Ÿå‚è€ƒ

### ç¯å¢ƒå˜é‡è®¾ç½®

```bash
export DASHSCOPE_API_KEY="sk-xxxxx"
export QWEN_MODEL="qwen-plus"
```

### å¸¸ç”¨å‘½ä»¤

```bash
# å®‰è£…SDK
pip install openai

# éªŒè¯API Key
python -c "from openai import OpenAI; print('OpenAI SDKå®‰è£…æˆåŠŸ')"
```

### å®˜æ–¹èµ„æºé“¾æ¥

- **ç™¾ç‚¼å¹³å°**ï¼šhttps://bailian.console.aliyun.com
- **å®˜æ–¹æ–‡æ¡£**ï¼šhttps://help.aliyun.com/zh/model-studio
- **APIå‚è€ƒ**ï¼šhttps://help.aliyun.com/zh/model-studio/use-qwen-by-calling-api
- **GitHub**ï¼šhttps://github.com/QwenLM

---

## ä¸ƒã€æ€»ç»“

Qwen APIæ˜¯ä¸€å¥—å¼ºå¤§è€Œçµæ´»çš„å¤§æ¨¡å‹æ¥å£ç³»ç»Ÿï¼š

âœ… **ä¼˜åŠ¿ï¼š**
- å…¼å®¹OpenAIåè®®ï¼Œè¿ç§»æˆæœ¬ä½
- æ¨¡å‹ä¸°å¯Œï¼Œæ”¯æŒå¤šç§ä¸“ä¸šåœºæ™¯
- ä»·æ ¼æœ‰ç«äº‰åŠ›ï¼Œç‰¹åˆ«æ˜¯è½»é‡æ¨¡å‹
- æ”¯æŒFunction Callingç­‰é«˜çº§åŠŸèƒ½
- æ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ´»è·ƒ

ğŸ“Œ **å…³é”®ç‚¹ï¼š**
- é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¾ˆé‡è¦
- ä¼˜åŒ–æç¤ºè¯èƒ½æå‡æ•ˆæœ
- å®æ–½é‡è¯•æœºåˆ¶æå‡å¯é æ€§
- ç›‘æ§æˆæœ¬é¿å…è¶…å‡ºé¢„ç®—

ğŸš€ **å»ºè®®è¡ŒåŠ¨ï¼š**
1. æ³¨å†Œç™¾ç‚¼å¹³å°è·å–API Key
2. ä»qwen-pluså¼€å§‹ä½“éªŒ
3. æ ¹æ®åœºæ™¯ä¼˜åŒ–æç¤ºè¯
4. ç›‘æ§ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬

